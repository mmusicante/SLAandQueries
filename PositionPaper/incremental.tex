We propose an SLA guided, continuous data provision and integration approach that consists in three steps  starting from the processing of the query  to the delivery of the results.
Figure~\ref{fig:arch} shows the general architecture of an SLA guided data integration system. It accesses data services which are data providers deployed in a cloud  that provide agreed SLA’s. 
Given a requirement expressing a query and quality of service preferences: cost, provenance, reputation, execution time, the system processes it  as follows: (i) derived SLA  computation for filtering possible data providers; (ii) query rewriting for computing services compositions that can be used for building results; (iii) managing the integration process including storing partial results, delivering adata and launching and re-launching queries. Intermediate results that are stored as knowledge in order to reduce the overhead of the query evaluation process. 
%The whole process is monitored to determine whether a computed SLA is being honoured while a query is evaluated. 

%These descriptions are stored in a directory together with meta-data about the way queries are evaluated for producing results. 
%The system uses this information  by query processing and monitoring modules for rewriting queries according to given quality of service (QoS) preferences expressed by a data consumer, for example a user.The following lines describe how this query is evaluated according to our approach. 

\begin{figure}
\includegraphics[width=0.5\textwidth]{figs/arch.png}
\caption{General architecture of an SLA guided  data integration system.\label{fig:arch}}
\end{figure}

In order to illustrate our approach, consider a smart city that aims at being energy self-sustainable and produce and consume, as much as possible, energy within its geographic area. 
Producers are characterized according to their location, the amount of energy in Kilowatts-hour that they can sell, the cost of that energy, and the time window in which they can produce it. 
Consumers are described by their location, their energy requirements during a certain interval of time, the maximum total cost they are ready to pay, and quality of service requirements such as availability and how critical it is to consume this amount of energy. 
An energy exchange market is established in order to continuously trade  energy provision/consumption ensuring that all consumers will have the energy they require at every moment.




Services are deployed in different cloud providers and each service exports an agreed SLA that specifies the economic cost per call, the maximum number of calls that can be done per day, the availability of the service, the average response time when a method is called, the reliability, the privacy of the produced data (whether they can be stored or not), the precision, freshness and provenance of the produced data. 

\begin{trivlist}\sf\footnotesize
\item[~$\bullet$ ] {\sf agreedSLA:$\langle$cost/call, maxCalls/day, availability, responseTime, reliability, privacy, precision, freshness, provenance$\rangle$}. 
  
 \end{trivlist}
 
As said in previous sections, some of these measures ({\sf cost/call, maxCall/day}) are static and explicitly specified by the service provider. 
In contrast, the other measures should be computed by monitoring the conversations between the service and the applications that contact it.  

In our example assume that there are several energy provision services ({\sf e$_1$, ... e$_n$}) that can be independent or hubs integrating several energy providers. 
Each of them is specified by a clause:
\begin{trivlist}\sf\footnotesize
\item[~$\bullet$ ]   e$_i$ $\equiv$ provider(KW-h, Ecost, rate, location), \textit{SLA}$_i$
\end{trivlist}

Cloud providers define also their SLA contracts defining normally subscription contracts that specify, the cost per request ({\sf cost/request}), the volume of data that can be exchanged per month ({\sf I/0 volume/month}), the cost of transferring data or applications within the same data centre or between data centres ({\sf datatransferCost/region}), the storage space ({\sf storageSpace}). For example some cloud providers enable the customer to choose the zone to install PaaS services and deploy applications (e.g. zone 1 is Europe). If the customer wishes to deploy services in zone 1 but store data in zone 2 the transfer cost will change.

\begin{trivlist}\sf\footnotesize
%\item[~$\bullet$ ] {\sf agreedSLA:$\langle$cost/call, maxCalls/day, availability, responseTime, reliability, privacy, precision, freshness, provenance$\rangle$}. 
% 
 \item[~$\bullet$ ]  {\sf cloudSLA:$\langle$cost/request, I/0 volume/month, datatransferCost/region, storageSpace$\rangle$}. 
 \end{trivlist}
 

According to our approach, energy producers are modelled as data services with associated ``agreed'' SLAs. In the example, we assume that several producers will be able to supply energy for a given period of time given specific  preferences expressed by a consumer. 
Assume that there are four household energy providers that can be queried individually and two hubs that collect information from the community smartmeters.
Hubs will store information about (surplus) energy, available from particular users.
We represent these services by {\sf e$_1$, \dots, e$_4$} and {\sf h$_1$ and h$_2$}.
We also suppose the existence of two free location services exporting the following interface: {\sf loc(IP) $\leftarrow$ $\langle$ X, Y$\rangle$}, meaning that given an IP address it returns a geographic position expressed as a pair of coordinates. 
All these services can potentially be combined for answering queries.



An energy request is expressed as a query that specifies an energy requirement with QoS preferences independently of the possible producers. 

Queries may be expressed as Datalog-like programs or an SQL-like expressions, including spatio-temporal attributes and preferences.
For instance, \textit{List of energy providers that can provision 1000 Kwatts/h, in the next 10 seconds, that are close to my city with a cost of 0,50 euros/Kwatt and that are labeled as green?}. 
The user preferences statement would include their cloud provider contract and quality preferences:

\begin{trivlist}\sf\footnotesize
\item[~$\bullet$ ]  {\sf cloudSLA:$\langle$0,05 cents per call, 8 Gigabytes I/0 volume/month, free, 1 Giga$\rangle$}. 
\item[~$\bullet$ ] {\sf preferencesStatement:$\langle$query total cost,  total responseTime, reliability, freshness, precision, provenance, storage$\rangle$}. 
\end{trivlist}


We consider a simplified SLA cloud contract inspired in the lowest contract provided by Azure: {\sf cost of \$0,05 cents per call,  8~GB of I/O volume/month, free data transfer cost within the same region,  01~GB of storage}. 
The user is ready to pay maximum {\sf \$5 as total query cost}; she requests that only {\sf green} energy providers are listed (provenance); at least {\sf 85$\%$} of precision of provided data, even if they are not fresh; she requires an availability rate of at least {\sf 90$\%$} and with a response time of {\sf 0,01 seconds}.
 





%-----------------------------------------------------------------
\section{Deriving a query SLA}
\label{sec:slaModel}
%-----------------------------------------------------------------

%\begin{itemize}
%\item Expression haut niveau du SLA en termes de préférences qui doit converger avec le SLA technique des services.
%  \begin{itemize}
%  \item (Souhait de temps de réponse, coût des services, espace de stockage,  
%  \item Templates pour exprimer le SLA
%  \item Intégration: modèle pivot de SLA
%\end{itemize}
%
%\item SLA violation contrôlée avec des mechanisms de monitoring.
%\item Que ce que devient l’intégration de données par rapport au SLA
%\item Création dynamique de SLA → niche de marché: étant donnée deux SLA fabriquer un SLA d’intégration
%\end{itemize}

The key and original aspect of   our proposed data integration and provision process is  defined as a vertical mapping of user QoS preferences and agreed SLAs. This  leads to a {\em derived SLA} that guides the evaluation of a query. 

A query has associated preferences  expressed as macroscopic constraints (i.e. user preferences statement): execution time, pay / no pay, data reliability, provenance, freshness, privacy, partial/full results, delivery mode. These constraints are coupled with the profile of the user which is in general stated in her cloud subscription (amount of assigned storage space, number of requests, I/O transfered Mega bytes, etc.). 



%One may think to a first filter to remove the individual services which do not meet some or all of the constraints expressed by the user. 

We assume that services export SLAs (i.e., agreed SLAs) that define measures   that can be either expressed as constants,  computed (dynamically) by monitoring the execution and conversations associted to services, and hybrid they can be statically stated  but they change at execution time.  A service  agreed SLA is expressed through an  XML document using the specification WSLA (Web service level agreement \footnote{\footnotesize http://www.research.ibm.com/people/a/akeller/\-Data/WSLASpecV1-20030128.pdf}). The service SLA measures  that we consider are: response time, availability, price/call, reliability, data production rate. Other measures are associated to the conditions in which the service is called or to the precision and recall of their produced data given a request. 

An example of computed measure is the cost of retrieving the list of energy providers within a region with their KWatt cost. The cost is determined by the  cost of the calls. This request  includes the price of calling a service (e.g.,  between 0,25 - 0,50 euros depending on the data service), plus the price of data transmision according to the amount of trasnmitted MegaOctets through the network and the type of subscription of the user for using the network. 
%Since we assume that services can be deployed on different cloud providers, measures and SLA threasholds can vary.



Given agreed SLA's and a user preferences statement the challenge is to compute a  {\em derived SLA} that  maps SLA measures and preferences attributes.  The derived SLA is defined as a set of measures that correspond to the user preferences computed as a function of different static, computed and hybrid measures. The {\em derived SLA}  will guide the way the query will be evaluated, and the way results will be computed and delivered.

In the example, some of the user preferences statement measures are used for defining a dervied SLA that, as said in previous section, will guide the evaluation of the query. These measures are defined as a function of the measures used by the agreed SLAs and by the cloud SLA contract.
\begin{trivlist}\sf\footnotesize
\item[~$\bullet$ ] query total cost: $\sum_{i = 1\dots n}$ cost(s$_i$) + data transfer $\leq$ \$5
 \item[~$\bullet$ ] total response time: of services + data transfer
 \item[~$\bullet$ ] availability: {\em (of services involved)} $\leq$ {\sf 90$\%$}, 
 \item[~$\bullet$ ] freshness: non 
 \item[~$\bullet$ ] precision: {\em avg (precision of services involved)} $\leq$ {\sf 85$\%$}
 \item[~$\bullet$ ] provenance:  all services involved must be $green$
 \item[~$\bullet$ ] storage: {\em partial results size} $\leq 1 Giga$ 
 \end{trivlist} 
 
Therefore, we propose a classification of SLA measures that represents the relationship between fine grained measures used by agreed SLAs and coarse grained measures used in user preferences statements. It specifies also how to compute coarse grained measures with fine grained ones. For example, data precision will be computed as a function of availability, freshness and provenance exported by data services. The derived SLA  can be seen as a set of inequations that have to be solved during the execution of a service composition. Since some of them can only be determined at execution time, the decision on which services will participate in the evaluation of the query is approximated. We will discuss this issue in the next sections.


This step may lead either to the rejection of integration in case of total incompatibility, or to a negotiation between SLA which will lead us to the proposal for a negotiated SLA integration and thus the need for an adaptive setting.
%
%
% \begin{enumerate}
%\item Computation of a global SLA given the existing possible SLA agreed by data providers that can be called for answering the query. Data providers are filtered in this way, since only those agreed SLA that can be combined into a global SLA that can fulfill the user preferences are considered for retrieving data.
%
 % 
%  \item Filter the data providers that can potentially participate in the evaluation of the query taking into consideration the preferences associated to the query.
  %
 % \item 
 Negociation of this type of SLA depends strongly on the request sent and the services deployed at the arrival time of the application on the cloud. This negotiation can be expensive and may not scale well.
 % \end{enumerate}


 
 
 Given a query and its preferences statement, the system  finds  service compositions that produce results   meeting the required constraints, as discussed in the following section.
 
%-----------------------------------------------------------------
\section{Query Rewriting}
\label{sec:queryRew}
%-----------------------------------------------------------------
%{\color{red}
%See wether a similar Q has been already rewritten or rewrite it. Executing a query requires first a semantic analysis which will subdivide R into a set of sub-queries, in such a way that each sub-query can be processed by a DataService deployed on the cloud.   The subqueries represent the possible combination of services that can answer the initial query with given SLA.
%}

Query rewriting is a well-known problem for the database community.
The problem consists in transforming an abstract query into a set (or list) of lower-level queries to the available databases.
Traditionally, the abstract query is a query over a set of views and the lower-level queries are performed on the available databases whose information compose the view. 
The rewriting is guided by the schema of both abstract and concrete databases.
The answers to the lower level queries are combined in order to obtain the result to be returned to the user.

The query rewriting problem may be generalized to the case of services.
Both database queries and service invocations may be represented using a similar syntax.
Indeed, the interfaces to relational databases and information-provision
%\footnote{Services that do not perform changes in the data they use.} 
services are exactly the same.
In this case, the query to be rewritten is seen as an abstract service composition, to be expressed in terms of concrete services.
%(which take the place of the available database queries).

The case of more general services (\textit{i.e}, services that maintain and update information) is a generalization of the information-provision case.
Unlike the simpler case, where only the service interfaces need to be considered, the general case requires considering the functional and non-functional aspects of the query and available services.
In this context, the \textit{Local as View} (\textit{LAV}) methods of query rewriting~\cite{Levy2000} are suitable.
In the LAV approach, the rewriting process is guided by the specification of both the query to be rewritten and the available databases.
In the case of general services, we can use the specification of the composition to be produced as well as the specification of each available service.
These specifications may detail both the functional and non-functional behaviour of each service, including SLA.

Query rewriting techniques have been adapted to the context of service composition~\cite{BBM10,ZLC11,CostaAMR13}. 
In~\cite{CostaAMR13} the authors present an algorithm to automatically refine high-level specifications of service compositions into lower-level ones. 
The method is based on the MiniCon algorithm~\cite{PH01} for query rewriting.
%known in the database domain.
The proposed approach consists in generating several translations of an abstract service specification into compositions
over concrete  services. 
The solutions proposed are ranked and may be coded into concrete workflows as shown in the following section.  The next example shows the main features of the approach proposed in~\cite{CostaAMR13} and that is extended in the case of SLA guided services based data integration. 

\begin{example}[Service Refinement by Rewriting]\label{Ex:rew1}
Let us consider the case of generating sales reports for a global bookstore.
This hypothetical bookstore sells books both at about 300 shops around the globe as well as via Internet.
The bookstore has four international warehouses, located in four different continents.
The bookstore uses the services of three different cloud providers.
Each cloud provider exports their own interfaces.

Local shops use the nearest cloud provider.
Internet transactions are processed by the Asian and South American cloud providers.

When an on-line client requires a list of books, a composed web service is generated, in order to fetch each book (from the nearest warehouse where the book is available) and to put in motion the payment and packing procedures.
Depending on the location of the client, different conditions may apply on the selling and payment procedures.
So, for each country or region, a limited number of options may be available for payment, packaging and delivery.
Additionally, non-functional requirements, defined by SLA may apply.

In this context, the user supplies the list of books, his location and payment information and a composite web service should be generated to fulfill the order.
The generated service composition should pick each book at the nearest warehouse, in order to minimize the costs of delivery and processing.
Additional requirements, such as delivery time, may apply.

In order to produce a personalised service composition for each user, the algorithm in~\cite{CostaAMR13} takes into account the specification of the composition (which may be produced by the user's browser, including context information).
The specification of each available service is also considered (this specification should be given by the service provider).
~\hfill\openbox
\end{example}

The next example illustrates one of the limits of the automatic composition algorithm.

\begin{example}[Incremental queries]\label{Ex:rew2}
Let us return to the global bookstore of Example~\ref{Ex:rew1}.
Let us suppose that the sales data is needed to produce daily and weekly ``\textit{Top 500}'' best-selling lists.
In this case, each warehouse database will be queried and the list will be produced by adding data obtained from them.
Let us supose that, in order to minimize the the communications between servers around the Globe, the \textit{Top 500} lists need to be produced incrementally.
In this case, the composition produced by the service refinement may need to include an iteration. The data produced by the warehouse servers will be processed in batch and the process will end once the list reaches the size of 500 titles.

As far as our knowledge, the incremental production of a solution is outside of the scope of the current methods for rewriting service compositions and represents a challenge to the area.
~\hfill\openbox
\end{example}


Given a a set of services that can possibly be composed and the derived SLA, a service cmposition must be produced.
Some of the inequations of the derived SLA should be included in the service compositions that answer the query.
In the case of our query example the following composition can be used for answering it:
\begin{eqnarray*}
Q_1 &\equiv&
   \langle X_1,Y_1\rangle = loc_1(IP), \\
&& \langle X_2,Y_2 \rangle = loc_1(Eprovider), \\
&& D = distance(\langle X_1,Y_1\rangle, \langle X_2,Y_2\rangle), \\
&& \langle C_1, E_1 \rangle = e_1(\dots), \dots \langle C_4, E_4 \rangle = e_4(\dots), \\
&& D \leq 1.5 \mathsf{Km},\ \ sum(C_1:C_4) \leq 5, \\
&& sum(E_1:E_4) \geq 1000\ \mathsf{kw-h}, \\
&& \mathsf{totalResponseTime}  \leq 10\ \mathsf{seg}
\end{eqnarray*}

  In fact our approach would generate a number $k$ of service compositions, combining as much as possible the services available such that the constraints of the derived SLA are verified. 
One challenge of this is to generate incremental queries.
 

%
%%-----------------------------------------------------------------
%\subsection{Executing optimized queries}
%\label{sec:queryOpt}
%%-----------------------------------------------------------------
%Given the query rewritten as a service composition, the idea is then to optimize them and execute them. In our approach these queries are implemented as query worflows. A query workflow implements a service composition defining activities and a control flow. An activity is a program that implements the interaction with a data service (through a method call) and the processing of the data it provides; it can also implement an data processing operation such as filter, aggregation, correlation. The control flow defines the order in which activities must be executed (sequencially or in parallel). Service compositions defining subqueries are transformed into query workflows.
%
%A query worflow can be optimized with respect to the preferences expressed in a user profile: the economic cost, the execution time, the energy necessary to execute it. Therefore, given a service coordination expressing a (sub)query we compute a search space of all possibile query workflows that can implement a query (all activities sequentially, as much activities in parallel as possible, conmuting activities). Each quey workflow has an estimated multi-dimensional cost, computing according to some measures of the computed SLA. The "optimum" query workflow is the one whose cost is the closest to the expected requirements of the user. Since the cost is multidimensional, several query workflows can be close to the user preferences. For this reason, we use a top-k algorithm for choosing an ordered set of "best" query workflows. One of these queries is executed by a workflow engine.
%
%
%A service composition (expressed in a Datalog-like syntax) is then transformed into a query workflow search space consisting of workflows with different control flows and where constraints serve to determine an optimization objective. 
%In the case of $Q_1$ above, the corresponding search space contains for example a workflow {\sf QW$_1$} where all activities are executed sequentially. 
%Another one, {\sf QW$_2$}, with parallel activities programming the call to a location service for the user and the energy providers, then a filter activity selecting only services located not farther to 1.5 Km, followed by  parallel activities that compute the total cost of the energy to buy, the total amount of energy. 
%    
%    Once the search space has been computed the QWs are filtered according to their economic and execution time costs. The QWs that minimize this cost are identified and ordered according to their conformance to the user preferences statement.

 
%-----------------------------------------------------------------
\section{Dealing with the resources consumed by the evaluation process}
\label{sec:queryProcessOpt}
%-----------------------------------------------------------------
% Indeed, let consider a request R launched by a user who specifies a %number of constraints on the environment execution. 
  
 %It is  crucial to provide proactive mechanisms for optimizing the production of such SLA. 
 
 Our data provision and integration approach relys on data services deployed on one or different providers and it is delivered as a DaaS. This DaaS  uses resources from a cloud and this use  is  guided by an economic model (stated in a cloud subscription) that puts a threshold on the amount of resources to be invested in a query evaluation process. It is thus important to optimize the use of these resources.
 
 We believe that the optimization of this process can occur at two levels: first at the level of agreed SLA exported by services.  Indeed, queries requesting the same services compositions will have clauses in their SLAs that are more conditions of use of the infrastructure (ie not storing the data produced by a service). Instead of recomputing the derived SLA every time, we propose to store it and reuse it for other queries. 
 
Second, precalculated queries and partial results can be also stored in cache or in a persistent supprt. Rewritting results can be also stored and reduce execution and resources consumption time when evaluating similar queries. Storing or not such SLAs will depend on the cloud subscription of the user the issued the query (data access, intermediate storage capacity , cost of storage , etc ... ).
%Given this proposal, we identify several issues:
%- Level modeling would require a model that allows the representation of SLA integration.
%- There should also be a template for representing the requirements expressed by the user
%- A mining component to identify, from the requirements expressed in the template by the user, and before the analysis of the application, the candidate integration SLA to use or adapt according to the request. This implies mapping between property and expressed clauses being.

As discussed in previous sections, the derived SLA associated to service compositions can have free measures that can only be evaluated at run-time. In order to do so, we assume that there is a monitoring system observing and aggregating events for computing resources consumption, execution and time cost, volumes of data transfered when services deliver results. These computations are used dynamically for instanciating free variables in the derived SLA and thus determine wether te contract is respected by the execution of a query. Since this is monitered dynamicalle, the evaluation of the query can be adapted if the SLA is not being respected anymore.


%%-----------------------------------------------------------------
%\subsection{SLA based data integration system}
%\label{sec:architecture}
%%-----------------------------------------------------------------
%\begin{figure}
%\includegraphics[width=0.5\textwidth]{figs/arch.png}
%\caption{General architecture of an SLA guided  data integration system.\label{fig:arch}}
%\end{figure}
%
%Figure~\ref{fig:arch} shows the general architecture of an SLA guided data integration system that is supported by data services which are data providers deployed in a cloud and that provide agreed SLA’s. 
%These descriptions are stored in a directory together with meta-data about the way queries are evaluated for producing results. 
%The system uses this information  by query processing and monitoring modules for rewriting queries according to given quality of service (QoS) preferences expressed by a data consumer, for example a user.
