%\color{red}
%


\color{black}
The advent of cloud computing has imposed a new   resource consuming model that focuses on
 the \textit{technical and economic} conditions to be fulfilled in order to access potentially unlimited resources. Integrating and processing heterogeneous data collections, calls for efficient methods for correlating, associating, and filtering them considering their "structural" characteristics (data variety that implies different formats and data models) and  their quality, e.g., trust, freshness, provenance, partial or total consistency. 
Existing data integration techniques have to be revisited considering weakly curated and modeled data sets. This can be done according to quality of service (QoS) requirements expressed by their consumers and Service Level Agreement (SLA) contracts exported by data services and cloud providers that host  these collections and deliver resources for executing  associated processing and integration processes.
In fact,  the interest of SLA has been demonstrated  in data analysis but has not been yet widely considered for integrating data. 
We believe in the benefits of SLA-based data integration as an approach for better meeting  user  requirements related to the conditions in which data is delivered and integrated, and on the quality of the data provided by services.
To do so, several granularities of SLA must be considered: first, at the cloud level: the SLA ensured by providers regarding data; then at the service level, as unit for accessing and processing data, to be sure to fulfill  specific  needs; and finally at the integration level i.e the possibility to process, correlate and integrate big data collections distributed across different cloud storage supports, providing different quality properties for data (trust, privacy, reliability, etc).


 
%To better understand our problem, let us consider an example from the domain of energy
%management. We assume we are interested in queries like: \textit{Give a list of energy providers that can provision 1000 KW-h, in the next 10 seconds, that are close to my city, with a cost of 0,50 Euro/KW-h and that are labelled as green?} \\
% The user demanded to apply a special encryption algorithm to sensitive data if data has to be transferred between providers or between physical sites during the integration process (Constraint1). Furthermore, the data providers could wish also that in case of a common use of their data within  an integration process, that this should be done assigning the less important privileges to the user w.r.t her credentials to access the different data (Constraint 2). We consider a simplified SLA cloud contract inspired in the cheapest contract provided by Azure: \textit{cost of \$0,05 cents per call,  8~GB of I/O volume/month, free data transfer cost within the same region,  1~GB of storage.} 
%The user is ready to pay a maximum of \textit{\$5 as total query cost}; she requests that only  \textit{green} energy providers should be  listed (provenance), with at least  \textit{85$\%$} of precision of provided data, even if they are not fresh; she requires an availability rate of at least 90$\%$ and a response time of  \textit{0,01 s}. She demands to contact only data providers with a threshold of trust . 

To better understand our problem, consider a massive open online course system (MOOC) where users produce and consume content according to the geographic area and the expertise of participants. 
Producers are characterized according to their location, the type and topic of  content  they can provide, the access conditions (e.g. cost, inscription, or exchange unit), and the time window in which they can produce content. 
Consumers are characterized by their location, their interests  during a certain interval of time, the maximum total cost they are ready to pay consuming content, or the resources they are ready to provide in order to get the service, and QoS requirements such as availability and how critical it is to consume a given type of content. Both producers and consumers have subscriptions to different cloud providers for dealing with content storage, processing and exchange.
The MOOC  aims at being privacy respectful of the producers and consumers participating in courses.
 Providers  and consumers can ask to minimize the transfer of personal data  when they share/consume content.  According to the level of trust associated to data providers, the MOOC can use privacy preserving technics to let users share content anonymously  (Constraint1). Furthermore,  data providers can  also wish to give restricted data access credentials w.r.t. to their own, when their data are used  within  an integration process (Constraint 2).  
 
 %that this should be done assigning the less important privileges to the user w.r.t her credentials to access the different data 


  From this scenario we identify a set of issues that have to be addressed. First, how can the user efficiently obtain  results for her queries such that they meet her QoS requirements while respecting her subscribed contracts with the involved cloud provider(s)?  The user knows the low-level clauses of her SLA contract but she does not have an idea about the resources required to satisfy her requirements (SLA exported by services, example of Constraint 1).  Second, data services contracts should not be neglected in an integration process (Constraint 2).   As data services are deployed in a multi-cloud context, there is a need to establish the rules to determine how integration can be done and in which conditions. Intuitively, integration can be  done enforcing all specified conditions; but it is also possible to  expect situations where conditions can only be verified partially. Furthermore,  matching data providers with requests and QoS preferences with SLA's can be computationally costly. For this reason  the results of  such a  complex process  should be capitalized for further integration requests. How can this be done? The first step is to propose an architecture that integrates all services participating in a data integration process that copes QoS and SLA's of the services that participate in this process for computing a given query. 
  
  
We have proposed such architecture in~\cite{BennaniGMV14}. With this architecture it is necessary to revisit the specification of the integration phases in order to show how to include QoS and SLA and thereby proposing a new way of dealing with a data production and consumption process, taking into account SLA formalism and clauses -especially security concerns-  heterogeneity among clouds. Furthermore, this paper introduces a preliminary solution addressing SLA-guided data integration focusing particularly on query rewriting addressing security issues. We assume that data services publish Agreed-SLA that describe their  static and dynamic QoS measures in specific registries.  Thanks to an extended query rewriting process, a new kind of SLA is derived to match user preferences with low level agreed SLAs exported by services. The derived SLA allows to choose  services (w.r.t user demands) that can contribute for answering a query. Once data services have been chosen, the integration process will be guided by an integration SLA, negotiated taking into account user requirements and inter-cloud contracts.
%  Particularly, for queries that call several services deployed  on different clouds. 
%  Among them first,Furthermore, for a non specialist user, she do not realize what is the level of ressources she need to apply the encryption level asked  for. 
%  As data services are deployed in a multi-cloud context, there is a need to establish the rules on how integration can be made. 
%  concerns the context in which data will be used among clouds when data services are deployed in a multi-cloud configuration. How can the specified services requirements be enforced? And finally, data integration in this context faces an heterogeneity problem at different levels but specially in the scenario we are interested in, in data deployment conditions, the SLA expression language, the level security is taken into account in SLA contract.

 
 
This paper is organized as follows. Section \ref{sec:relWork} presents related works that address SLA modelling, integration and SLA guided data management processes in cloud environments. Section \ref{sec:incremental} gives an overview of our approach and highlights the need of new kind of SLA to conduct the integration process. Section \ref{sec:derivedSla}, \ref{sec:queryRew} and \ref{sec:queryProcessOpt} give an idea of the main steps of our proposal.  Finally section  \ref{sec:conclusions} concludes the paper and discusses future work.
%Section \ref{sec:useCase} presents a use case for illustrating the interest and use of our approach. 









 